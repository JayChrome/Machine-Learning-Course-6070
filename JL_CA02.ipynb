{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee3946ca-4756-478f-abee-8359e2472384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section we are importing libraries\n",
    "# The OS module in Python provides functions for creating and removing a directory (folder), fetching its contents, changing and identifying the current directory\n",
    "# Import numpy allows us to turn our dataframe into an array\n",
    "# Counter is an unordered collection where elements are stored as Dict keys and their count as dict value. \n",
    "#Sklearn naive bayes and metrics will help us run the model and get an accuracy score\n",
    "#Import time allows us to work with time\n",
    "#from subprocess import check_output gets the output of the calling program in python.\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from subprocess import check_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5919651-6cc8-4952-9747-b5b3799c90f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function \"make_Dictionary(root_dir)\" that takes one argument \n",
    "def make_Dictionary(root_dir): \n",
    "#Store all of the values from the function into a dataframe called all_words\n",
    "  all_words = []\n",
    "#Join paths of the files that are in the df root_dir. for every file that is in the root_dir, store it to a variable named \"emails\", For every mail item within emails\n",
    "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
    "#Create a for loop and iterate over the function.   \n",
    "  for mail in emails:\n",
    "#With mail as m\n",
    "    with open(mail) as m:\n",
    "#With mail as m\n",
    "      for line in m:\n",
    "#Split the line and store it in a variable called \"all_words\"\n",
    "        words = line.split()\n",
    "#Add the count of \"words\" to \"all_words\" for every \"words\" found\n",
    "        all_words += words\n",
    "#Convert the dictionary into a list and store it in \"list_to_remove\"\n",
    "  dictionary = Counter(all_words)\n",
    "#For every item in \"list_to_remove\"\n",
    "  list_to_remove = list(dictionary)\n",
    "#For every item in \"list_to_remove\"\n",
    "  for item in list_to_remove:\n",
    "    #\n",
    "    if item.isalpha() == False:\n",
    "#if the item is in the dicitionary, delete it\n",
    "      del dictionary[item]\n",
    "#If the item in the list does not return false, and if the item is not euqal 1,\n",
    "    elif len(item) == 1:\n",
    "      del dictionary[item]\n",
    "#return a liist of the most 3000 most common elements from the list and store it in a variable name \"dictionary\"\n",
    "  dictionary = dictionary.most_common(3000)\n",
    "#Add an argument to \"make_dictionary(root_dir)\" function and then the code will return the dictionary \n",
    "  return dictionary\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41f9ef7f-a1e3-43c6-840f-e8b20933262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mail_dir = mail directory\n",
    "#Create a function named \"extract_features(mail_dir):\" that takes one argument, mail directory\n",
    "def extract_features(mail_dir):\n",
    "#Join paths of the files that are in the mail_dir by Iterating through each file in mail_dr to get a list of all the files and the directories that they are in. Store it in a variable named \"files\"\n",
    "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
    "#Take the length of 3000 files and create an array of zeros. Store the array in a variable named \"features_matrix\".\n",
    "  features_matrix = np.zeros((len(files),3000))\n",
    "#Create an array that is the size of files, but will all zeros. Store that array in a variable named \"train_labels\"\n",
    "  train_labels = np.zeros(len(files))\n",
    "#Store 1 into a variable named \"count\"\n",
    "  count = 1;\n",
    "#Store 0 into a variable named \"docID\"\n",
    "  docID = 0;\n",
    "#Create a loop - for fil (a file) in files\n",
    "  for fil in files:\n",
    "#Open the files\n",
    "    with open(fil) as fi:\n",
    "#Count every line item in fi for each iteration\n",
    "      for i, line in enumerate(fi):\n",
    "#If i equals 2\n",
    "        if i ==2:\n",
    "#Then split the string and store it in a variable named \"words\" - what is the delimeter         \n",
    "          words = line.split()\n",
    "#For every word in the df word\n",
    "          for word in words:\n",
    "#Make 0 the WordID\n",
    "            wordID = 0\n",
    "#For every item in dictionary, Count dictionary for every iteration of i\n",
    "            for i, d  in enumerate(dictionary):\n",
    "#Store the count of words into d, an empty list \n",
    "              if d[0] == word:\n",
    "#io = WordID\n",
    "                wordID = i\n",
    "#Count word in the variable words and store it in the variable, \"features_matrix\" and variables features in columns docID, wordID\"\n",
    "                features_matrix[docID,wordID] = words.count(word)\n",
    "#Create a variable called \"train_labels\" and make \"docID\" column feature equal to 0\n",
    "      train_labels[docID] = 0;\n",
    "#Split the text based on slash and store it into a variable \"filepathTokens\"\n",
    "      filepathTokens = fil.split('/')\n",
    "#The below word block is tokenizing the text and every time the word appears, it increases the count of the word frequency by 1 \n",
    "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
    "      if lastToken.startswith(\"spmsg\"):\n",
    "        train_labels[docID] = 1;\n",
    "        count = count + 1\n",
    "      docID = docID + 1\n",
    "  return features_matrix, train_labels                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7fc20-f405-427e-9f92-a73e0e95b518",
   "metadata": {},
   "source": [
    "#Provide the path for the file names \n",
    "\n",
    "TRAIN_DIR = \"./train-mails\"\n",
    "TEST_DIR = \"./test-mails\"\n",
    "\n",
    "#os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104625a7-7a69-4ea8-bfe0-dd7c6b00c525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n"
     ]
    }
   ],
   "source": [
    "#create a new variable, dictionary where the train directory is included in the fucntion, make_dictionary\n",
    "dictionary = make_Dictionary(TRAIN_DIR)\n",
    "\n",
    "#Read and process the emails from the train and test folders \n",
    "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
    "features_matrix, labels = extract_features(TRAIN_DIR)\n",
    "test_features_matrix, test_labels = extract_features(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82e91a-88c2-41ae-a5b9-2b849d27dcb7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using Gaussian Naive Bayes Model for Classification\n",
    "clf = GaussianNB()\n",
    "print(\"Training Model using Gaussian naive Bayes algorithm...\")\n",
    "\n",
    "#fit the data to the model\n",
    "clf.fit(features_matrix,labels)\n",
    "print(\"Training completed\")\n",
    "print (\"Testing training model to predict Test labels.\")\n",
    "\n",
    "#test the data predictions\n",
    "y_pred = clf.predict(test_features_matrix)\n",
    "print(\"Completed classification of the Test data... now printing Accuracy Score by comparing predicted labels with Test labels.\")\n",
    "print(\"Accuracy Score:\", accuracy_score(test_labels, y_pred))     \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
